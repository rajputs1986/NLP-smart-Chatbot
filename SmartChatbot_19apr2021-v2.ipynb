{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference: https://www.youtube.com/watch?v=9KZwRBg4-P0\n",
    "#import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #see impact of TfidfVectorizer and see each of their usage\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get article from source\n",
    "article = Article(url = 'https://en.wikipedia.org/wiki/Natural_language_processing')\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "corpus = article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return a greeting response to user greeting\n",
    "def greeting_response(text):\n",
    "    \n",
    "    #bot greetings\n",
    "    bot_greetings = ['howdy', 'hi', 'hey', 'hola', 'hello']\n",
    "    \n",
    "    #user greetings\n",
    "    user_greetings = ['hi', 'hey', 'hello', 'greetings', 'wasup']\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in user_greetings:\n",
    "            return random.choice(bot_greetings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing the raw text\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bot response\n",
    "def bot_response(user_input):\n",
    "    sentence_list.append(user_input)\n",
    "    bot_response = ''\n",
    "    \n",
    "    #cm = CountVectorizer().fit_transform(sentence_list)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sentence_list)\n",
    "    \n",
    "    similarity_scores = cosine_similarity(tfidf[-1], tfidf)\n",
    "    \n",
    "    similarity_scores_list = similarity_scores.flatten() #reduce dimension of similarity_scores\n",
    "    indexes_similar_low_to_high = similarity_scores_list.argsort() #1st index show similiarity of sentence to itself\n",
    "    \n",
    "    sorted_values = sorted(similarity_scores_list)\n",
    "    \n",
    "    #print(len(similarity_scores_list))\n",
    "    #print(similarity_scores_list)\n",
    "    #print(indexes_similar_low_to_high)\n",
    "    #print(sorted_values)\n",
    "    \n",
    "    if(sorted_values[-2] == 0):\n",
    "        bot_response += \"I am sorry! I don't understand you\"\n",
    "    else:\n",
    "        for i in range(-3,-1,1):\n",
    "            bot_response += ' '+sentence_list[indexes_similar_low_to_high[i]] #pick the most similar sentence after sentence itself\n",
    "\n",
    "    return bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(-3,-1,1):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "##numpy array argsort example\n",
    "#ar = [10, 1, 11, 5]\n",
    "#arr = np.array(ar)\n",
    "#arr.argsort()\n",
    "#arr.argsort()[-2]\n",
    "#print(arr.sort())\n",
    "#print(sorted(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strart chat\n",
    "print('Bot: Hi am here to help you on general queries on NLP. Type your queries.')\n",
    "\n",
    "chat_exist_list = ['bye', 'talk to you later', 'good bye', 'exit', 'quit', 'break', 'hang up', 'bye see you']\n",
    "\n",
    "while(True):\n",
    "    user_input = input()\n",
    "    \n",
    "    if(user_input.lower() in chat_exist_list):\n",
    "        print('Bot: See you later')\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        #print(greeting_response(user_input.lower()))\n",
    "        if(greeting_response(user_input.lower()) != None):\n",
    "            print('Bot: '+ greeting_response(user_input.lower()))\n",
    "        else:\n",
    "            print('Bot: '+ bot_response(user_input.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-carpet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-casino",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
